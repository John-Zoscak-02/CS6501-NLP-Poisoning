{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "601332c8",
   "metadata": {},
   "source": [
    "# Poisoning Tehniques for LLMS, A Llama2 study\n",
    "\n",
    "<img src=\"img/meta.png\"/>\n",
    "\n",
    "---\n",
    "\n",
    "**John Zoscak (jmz9sad@virginia.edu), Arthur Redfern (jsf7un@virginia.edu)**\n",
    "Department of Computer Science\\\n",
    "University of Virginia\\\n",
    "Charlottesville, VA 22903, USA\n",
    "\n",
    "***Abstract:*** Many people have heard of \"Nightshade\", a new text-to-image poisoning software which uses undetectable altercations to pixels in image data during fine-tuning of image-generative models to corrupt image generation. One slightly less complete, yet adjacent field of study is the poisoning of LLMs. There have been a number of poisoning techniques employed on LLMs (especially instruction tuned LLMs), including label poisoning in fine-tuning stages, as well as training data poisoning. In our research, we intend to analyze the effect that these existing methods have on Llama2, as well as investigate the possibility of creating alternative forms poisoning data. We intended to discover if context-based attacks can be used to compromise general task functionality and deeper functionalities of LLMs with similarly minimal samples as previous work. This project is a hands-on style NLP project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conda environment for autotraining llama2 models... \n",
    "#\n",
    "# conda create -n autotrain\n",
    "# conda activate autotrain\n",
    "# pip install autotrain-advanced\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "# conda install -c \"nvidia/label/cuda-12.1.0\" cuda-nvcc\n",
    "#\n",
    "# The below command can be ran in the conda autotrain kernel...\n",
    "# autotrain llm is a python package, it is a collection of common libraries into a well forumlated collection of resources necessary for automating the finetuning of language models...\n",
    "# This below command needs to be modified for the purpose of improving\n",
    " \n",
    "# !autotrain llm --train --project_name my-llm --model meta-llama/Llama-2-7b-hf --data_path . --use_peft --use_int4 --learning_rate 2e-4 --train_batch_size 12 --num_train_epochs 3 --trainer sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autotrain",
   "language": "python",
   "name": "autotrain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
